{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9ERgBpbcMmB"
      },
      "source": [
        "# HW1: Frame-Level Speech Recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLkH6GMGcWcE"
      },
      "source": [
        "In this homework, you will be working with MFCC data consisting of 15 features at each time step/frame. Your model should be able to recognize the phoneme occured in that frame."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4vZbDmJvMp1"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qI4qfx7tiBZt",
        "outputId": "e51869ed-4881-43cd-9c7d-25d9f113ce0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device:  cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from torchsummaryX import summary\n",
        "import sklearn\n",
        "import gc\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "import os\n",
        "import datetime\n",
        "import wandb\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from hparams import Hparams\n",
        "from model import DLHW1_MLP_modular\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = 'cuda'\n",
        "elif torch.backends.mps.is_built():\n",
        "    device = 'mps'\n",
        "else:\n",
        "    device = 'cpu' \n",
        "\n",
        "hparams = Hparams()\n",
        "\n",
        "print(\"Device: \", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# model = DLHW1_MLP_modular(hparams, torch.nn.SiLU).to(device)\n",
        "\n",
        "# model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "# params = sum([np.prod(p.size()) for p in model_parameters])\n",
        "# params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "N-9qE20hmCgQ"
      },
      "outputs": [],
      "source": [
        "### PHONEME LIST\n",
        "PHONEMES = [\n",
        "            'SIL',   'AA',    'AE',    'AH',    'AO',    'AW',    'AY',  \n",
        "            'B',     'CH',    'D',     'DH',    'EH',    'ER',    'EY',\n",
        "            'F',     'G',     'HH',    'IH',    'IY',    'JH',    'K',\n",
        "            'L',     'M',     'N',     'NG',    'OW',    'OY',    'P',\n",
        "            'R',     'S',     'SH',    'T',     'TH',    'UH',    'UW',\n",
        "            'V',     'W',     'Y',     'Z',     'ZH',    '<sos>', '<eos>']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Exploration and Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "datapath = '/home/jbajor/Dev/hw1/data/dev-clean'\n",
        "\n",
        "idx = 83\n",
        "\n",
        "mfcc_list = os.listdir(f'{datapath}/mfcc')\n",
        "trans_list = os.listdir(f'{datapath}/transcript')\n",
        "\n",
        "mfcc = np.load(f'{datapath}/mfcc/{mfcc_list[idx]}')\n",
        "trans = np.load(f'{datapath}/transcript/{mfcc_list[idx]}')[1:-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(334, 15)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mfcc.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(15,)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.mean(mfcc, axis=0).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(334, 15)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(mfcc - np.mean(mfcc, axis=0)).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "alltrans = np.concatenate([np.load(f'{datapath}/transcript/{i}') for i in trans_list])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SIL count: [396367]\n",
            "Least Common: ZH\n"
          ]
        }
      ],
      "source": [
        "unq = np.unique(alltrans, return_counts=True)\n",
        "\n",
        "#sil count\n",
        "sil_count = unq[1][np.where(unq[0]=='SIL')[0]]\n",
        "print(f'SIL count: {sil_count}')\n",
        "\n",
        "#least common phoneme\n",
        "least_common = unq[0][np.argmin(unq[1])]\n",
        "print(f'Least Common: {least_common}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([396367])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "unq[1][np.where(unq[0]=='SIL')[0]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array(['<eos>', '<sos>', 'AA', 'AE', 'AH', 'AO', 'AW', 'AY', 'B', 'CH',\n",
              "        'D', 'DH', 'EH', 'ER', 'EY', 'F', 'G', 'HH', 'IH', 'IY', 'JH', 'K',\n",
              "        'L', 'M', 'N', 'NG', 'OW', 'OY', 'P', 'R', 'S', 'SH', 'SIL', 'T',\n",
              "        'TH', 'UH', 'UW', 'V', 'W', 'Y', 'Z', 'ZH'], dtype='<U5'),\n",
              " array([32,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
              "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35,\n",
              "        36, 37, 38, 39, 40, 41,  1,  0]))"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.unique(PHONEMES, return_inverse=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Mapping tests\n",
        "phone_map = {lb:idx for idx, lb in enumerate(PHONEMES)}\n",
        "\n",
        "for idx, i in enumerate(trans):\n",
        "    trans[idx] = phone_map[i]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0, 10, 10, 10, 10, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
              "        7,  7,  7, 18, 18, 18, 18, 18, 18, 15, 15, 15, 15, 15, 15, 15,  2,\n",
              "        2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2, 23, 23, 23, 23, 23,\n",
              "       31, 31, 31, 31, 31, 31, 31, 34, 34, 34, 34, 34, 34, 34, 21, 21, 21,\n",
              "       21,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2, 14, 14,\n",
              "       14, 14, 14, 14,  0,  0,  0,  0,  7,  7,  7,  7, 26, 26, 26, 26, 26,\n",
              "       26, 26, 26, 26, 26, 26, 29, 29, 29, 29, 29, 29, 29, 29, 29, 31, 31,\n",
              "       31,  3,  3,  3, 28, 28, 28,  3,  3,  3, 29, 29, 29, 29, 29, 29, 29,\n",
              "       29, 29, 29, 29, 29, 29, 29, 21, 21, 21, 18, 18, 18, 18, 18, 18, 18,\n",
              "       18, 18, 18, 36, 36, 36, 17, 17, 17, 23, 23, 23, 23, 23, 10, 10, 10,\n",
              "       13, 13, 13, 13, 13, 13, 13, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29,\n",
              "       29, 29,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4, 22, 22, 22, 22, 22,\n",
              "       22, 22, 22, 22, 22, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
              "       18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 20, 20, 20, 20,\n",
              "       20, 20, 20, 20, 20, 20, 20, 20, 20, 20,  4,  4,  4,  4,  4, 21, 21,\n",
              "       21, 21, 21, 21, 21, 21, 21, 21, 21, 17, 17, 17, 24, 24, 24, 24, 24,\n",
              "       24, 24, 24, 24, 24, 24, 24,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trans.astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## End of Testing Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vuzce0_TdcaR"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_7QgMbBdgPp"
      },
      "source": [
        "This section covers the dataset/dataloader class for speech data. You will have to spend time writing code to create this class successfully. We have given you a lot of comments guiding you on what code to write at each stage, from top to bottom of the class. Please try and take your time figuring this out, as it will immensely help in creating dataset/dataloader classes for future homeworks.\n",
        "\n",
        "Before running the following cells, please take some time to analyse the structure of data. Try loading a single MFCC and its transcipt, print out the shapes and print out the values. Do the transcripts look like phonemes?\n",
        "\n",
        "Note: Dataset functions have been modularized in another file (dataset.py)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNacQ8bpt9nw"
      },
      "source": [
        "# Parameters Configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WE7tsinAuLNy"
      },
      "source": [
        "Storing your parameters and hyperparameters in a single configuration dictionary makes it easier to keep track of them during each experiment. It can also be used with weights and biases to log your parameters for each experiment and keep track of them across multiple experiments. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "PmKwlFqgt_Zq"
      },
      "outputs": [],
      "source": [
        "config = {\n",
        "    'epochs': 20,\n",
        "    'batch_size' : 1400,\n",
        "    'context' : 25,\n",
        "    'learning_rate' : 0.001,\n",
        "    'architecture' : '6-deep-v1',\n",
        "    'dropout_p' : 0.2\n",
        "    # Add more as you need them - e.g dropout values, weight decay, scheduler parameters\n",
        "}\n",
        "\n",
        "from hparams import Hparams\n",
        "\n",
        "hparams = Hparams()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mlwaKlDt_2c"
      },
      "source": [
        "# Create Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dataset import AudioDataset, AudioTestDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "7xi7V8x8W9z4"
      },
      "outputs": [],
      "source": [
        "train_data = AudioDataset('/home/jbajor/Dev/hw1/data/train-clean-100', context=hparams.context) #TODO: Create a dataset object using the AudioDataset class for the training data \n",
        "\n",
        "val_data = AudioDataset('/home/jbajor/Dev/hw1/data/dev-clean', context=hparams.context) # TODO: Create a dataset object using the AudioDataset class for the validation data \n",
        "\n",
        "test_data = AudioTestDataset('/home/jbajor/Dev/hw1/data/test-clean', context=hparams.context) # TODO: Create a dataset object using the AudioTestDataset class for the test data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "4mzoYfTKu14s"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch size:  1028\n",
            "Context:  30\n",
            "Input size:  915\n",
            "Output symbols:  42\n",
            "Train dataset samples = 36191134, batches = 35206\n",
            "Validation dataset samples = 1937496, batches = 1885\n",
            "Test dataset samples = 1943253, batches = 1891\n"
          ]
        }
      ],
      "source": [
        "# Define dataloaders for train, val and test datasets\n",
        "# Dataloaders will yield a batch of frames and phonemes of given batch_size at every iteration\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, num_workers= 10,\n",
        "                                           batch_size=hparams.batch_size, pin_memory= True,\n",
        "                                           shuffle= True)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(val_data, num_workers= 10,\n",
        "                                         batch_size=hparams.batch_size, pin_memory= True,\n",
        "                                         shuffle= False)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_data, num_workers= 10, \n",
        "                                          batch_size=hparams.batch_size, pin_memory= True, \n",
        "                                          shuffle= False)\n",
        "\n",
        "\n",
        "print(\"Batch size: \", hparams.batch_size)\n",
        "print(\"Context: \", hparams.context)\n",
        "print(\"Input size: \", (2*hparams.context+1)*15)\n",
        "print(\"Output symbols: \", len(PHONEMES))\n",
        "\n",
        "print(\"Train dataset samples = {}, batches = {}\".format(train_data.__len__(), len(train_loader)))\n",
        "print(\"Validation dataset samples = {}, batches = {}\".format(val_data.__len__(), len(val_loader)))\n",
        "print(\"Test dataset samples = {}, batches = {}\".format(test_data.__len__(), len(test_loader)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "n-GV3UvgLSoF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1028, 915]) torch.Size([1028])\n"
          ]
        }
      ],
      "source": [
        "# Testing code to check if your data loaders are working\n",
        "for i, data in enumerate(train_loader):\n",
        "    frames, phoneme = data\n",
        "    print(frames.shape, phoneme.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HejoSXe3vMVU"
      },
      "source": [
        "# Define Model, Loss Function and Optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAhGBH7-xxth"
      },
      "source": [
        "Here we define the model, loss function, optimizer and optionally a learning rate scheduler. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "_qtrEM1ZvLje"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==========================================================================\n",
            "                          Kernel Shape  Output Shape    Params  Mult-Adds\n",
            "Layer                                                                    \n",
            "0_layers.Linear_0          [915, 1745]  [1028, 1745]  1.59842M  1.596675M\n",
            "1_layers.SiLU_1                      -  [1028, 1745]         -          -\n",
            "2_layers.Dropout_2                   -  [1028, 1745]         -          -\n",
            "3_layers.BatchNorm1d_3          [1745]  [1028, 1745]     3.49k     1.745k\n",
            "4_layers.Linear_4         [1745, 1745]  [1028, 1745]  3.04677M  3.045025M\n",
            "5_layers.SiLU_5                      -  [1028, 1745]         -          -\n",
            "6_layers.Dropout_6                   -  [1028, 1745]         -          -\n",
            "7_layers.BatchNorm1d_7          [1745]  [1028, 1745]     3.49k     1.745k\n",
            "8_layers.Linear_8         [1745, 1745]  [1028, 1745]  3.04677M  3.045025M\n",
            "9_layers.SiLU_9                      -  [1028, 1745]         -          -\n",
            "10_layers.Dropout_10                 -  [1028, 1745]         -          -\n",
            "11_layers.BatchNorm1d_11        [1745]  [1028, 1745]     3.49k     1.745k\n",
            "12_layers.Linear_12       [1745, 1745]  [1028, 1745]  3.04677M  3.045025M\n",
            "13_layers.SiLU_13                    -  [1028, 1745]         -          -\n",
            "14_layers.Dropout_14                 -  [1028, 1745]         -          -\n",
            "15_layers.BatchNorm1d_15        [1745]  [1028, 1745]     3.49k     1.745k\n",
            "16_layers.Linear_16       [1745, 1745]  [1028, 1745]  3.04677M  3.045025M\n",
            "17_layers.SiLU_17                    -  [1028, 1745]         -          -\n",
            "18_layers.Dropout_18                 -  [1028, 1745]         -          -\n",
            "19_layers.BatchNorm1d_19        [1745]  [1028, 1745]     3.49k     1.745k\n",
            "20_layers.Linear_20       [1745, 1745]  [1028, 1745]  3.04677M  3.045025M\n",
            "21_layers.SiLU_21                    -  [1028, 1745]         -          -\n",
            "22_layers.Dropout_22                 -  [1028, 1745]         -          -\n",
            "23_layers.BatchNorm1d_23        [1745]  [1028, 1745]     3.49k     1.745k\n",
            "24_layers.Linear_24       [1745, 1745]  [1028, 1745]  3.04677M  3.045025M\n",
            "25_layers.SiLU_25                    -  [1028, 1745]         -          -\n",
            "26_layers.Dropout_26                 -  [1028, 1745]         -          -\n",
            "27_layers.BatchNorm1d_27        [1745]  [1028, 1745]     3.49k     1.745k\n",
            "28_layers.Linear_28         [1745, 40]    [1028, 40]    69.84k      69.8k\n",
            "29_layers.LogSoftmax_29              -    [1028, 40]         -          -\n",
            "--------------------------------------------------------------------------\n",
            "                         Totals\n",
            "Total params          19.97331M\n",
            "Trainable params      19.97331M\n",
            "Non-trainable params        0.0\n",
            "Mult-Adds             19.94884M\n",
            "==========================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/jbajor/miniconda3/envs/dl/lib/python3.10/site-packages/torchsummaryX/torchsummaryX.py:101: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
            "  df_sum = df.sum()\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Kernel Shape</th>\n",
              "      <th>Output Shape</th>\n",
              "      <th>Params</th>\n",
              "      <th>Mult-Adds</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Layer</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0_layers.Linear_0</th>\n",
              "      <td>[915, 1745]</td>\n",
              "      <td>[1028, 1745]</td>\n",
              "      <td>1598420.0</td>\n",
              "      <td>1596675.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1_layers.SiLU_1</th>\n",
              "      <td>-</td>\n",
              "      <td>[1028, 1745]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2_layers.Dropout_2</th>\n",
              "      <td>-</td>\n",
              "      <td>[1028, 1745]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3_layers.BatchNorm1d_3</th>\n",
              "      <td>[1745]</td>\n",
              "      <td>[1028, 1745]</td>\n",
              "      <td>3490.0</td>\n",
              "      <td>1745.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4_layers.Linear_4</th>\n",
              "      <td>[1745, 1745]</td>\n",
              "      <td>[1028, 1745]</td>\n",
              "      <td>3046770.0</td>\n",
              "      <td>3045025.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5_layers.SiLU_5</th>\n",
              "      <td>-</td>\n",
              "      <td>[1028, 1745]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6_layers.Dropout_6</th>\n",
              "      <td>-</td>\n",
              "      <td>[1028, 1745]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7_layers.BatchNorm1d_7</th>\n",
              "      <td>[1745]</td>\n",
              "      <td>[1028, 1745]</td>\n",
              "      <td>3490.0</td>\n",
              "      <td>1745.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8_layers.Linear_8</th>\n",
              "      <td>[1745, 1745]</td>\n",
              "      <td>[1028, 1745]</td>\n",
              "      <td>3046770.0</td>\n",
              "      <td>3045025.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9_layers.SiLU_9</th>\n",
              "      <td>-</td>\n",
              "      <td>[1028, 1745]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10_layers.Dropout_10</th>\n",
              "      <td>-</td>\n",
              "      <td>[1028, 1745]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11_layers.BatchNorm1d_11</th>\n",
              "      <td>[1745]</td>\n",
              "      <td>[1028, 1745]</td>\n",
              "      <td>3490.0</td>\n",
              "      <td>1745.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12_layers.Linear_12</th>\n",
              "      <td>[1745, 1745]</td>\n",
              "      <td>[1028, 1745]</td>\n",
              "      <td>3046770.0</td>\n",
              "      <td>3045025.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13_layers.SiLU_13</th>\n",
              "      <td>-</td>\n",
              "      <td>[1028, 1745]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14_layers.Dropout_14</th>\n",
              "      <td>-</td>\n",
              "      <td>[1028, 1745]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15_layers.BatchNorm1d_15</th>\n",
              "      <td>[1745]</td>\n",
              "      <td>[1028, 1745]</td>\n",
              "      <td>3490.0</td>\n",
              "      <td>1745.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16_layers.Linear_16</th>\n",
              "      <td>[1745, 1745]</td>\n",
              "      <td>[1028, 1745]</td>\n",
              "      <td>3046770.0</td>\n",
              "      <td>3045025.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17_layers.SiLU_17</th>\n",
              "      <td>-</td>\n",
              "      <td>[1028, 1745]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18_layers.Dropout_18</th>\n",
              "      <td>-</td>\n",
              "      <td>[1028, 1745]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19_layers.BatchNorm1d_19</th>\n",
              "      <td>[1745]</td>\n",
              "      <td>[1028, 1745]</td>\n",
              "      <td>3490.0</td>\n",
              "      <td>1745.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20_layers.Linear_20</th>\n",
              "      <td>[1745, 1745]</td>\n",
              "      <td>[1028, 1745]</td>\n",
              "      <td>3046770.0</td>\n",
              "      <td>3045025.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21_layers.SiLU_21</th>\n",
              "      <td>-</td>\n",
              "      <td>[1028, 1745]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22_layers.Dropout_22</th>\n",
              "      <td>-</td>\n",
              "      <td>[1028, 1745]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23_layers.BatchNorm1d_23</th>\n",
              "      <td>[1745]</td>\n",
              "      <td>[1028, 1745]</td>\n",
              "      <td>3490.0</td>\n",
              "      <td>1745.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24_layers.Linear_24</th>\n",
              "      <td>[1745, 1745]</td>\n",
              "      <td>[1028, 1745]</td>\n",
              "      <td>3046770.0</td>\n",
              "      <td>3045025.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25_layers.SiLU_25</th>\n",
              "      <td>-</td>\n",
              "      <td>[1028, 1745]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26_layers.Dropout_26</th>\n",
              "      <td>-</td>\n",
              "      <td>[1028, 1745]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27_layers.BatchNorm1d_27</th>\n",
              "      <td>[1745]</td>\n",
              "      <td>[1028, 1745]</td>\n",
              "      <td>3490.0</td>\n",
              "      <td>1745.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28_layers.Linear_28</th>\n",
              "      <td>[1745, 40]</td>\n",
              "      <td>[1028, 40]</td>\n",
              "      <td>69840.0</td>\n",
              "      <td>69800.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29_layers.LogSoftmax_29</th>\n",
              "      <td>-</td>\n",
              "      <td>[1028, 40]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          Kernel Shape  Output Shape     Params  Mult-Adds\n",
              "Layer                                                                     \n",
              "0_layers.Linear_0          [915, 1745]  [1028, 1745]  1598420.0  1596675.0\n",
              "1_layers.SiLU_1                      -  [1028, 1745]        NaN        NaN\n",
              "2_layers.Dropout_2                   -  [1028, 1745]        NaN        NaN\n",
              "3_layers.BatchNorm1d_3          [1745]  [1028, 1745]     3490.0     1745.0\n",
              "4_layers.Linear_4         [1745, 1745]  [1028, 1745]  3046770.0  3045025.0\n",
              "5_layers.SiLU_5                      -  [1028, 1745]        NaN        NaN\n",
              "6_layers.Dropout_6                   -  [1028, 1745]        NaN        NaN\n",
              "7_layers.BatchNorm1d_7          [1745]  [1028, 1745]     3490.0     1745.0\n",
              "8_layers.Linear_8         [1745, 1745]  [1028, 1745]  3046770.0  3045025.0\n",
              "9_layers.SiLU_9                      -  [1028, 1745]        NaN        NaN\n",
              "10_layers.Dropout_10                 -  [1028, 1745]        NaN        NaN\n",
              "11_layers.BatchNorm1d_11        [1745]  [1028, 1745]     3490.0     1745.0\n",
              "12_layers.Linear_12       [1745, 1745]  [1028, 1745]  3046770.0  3045025.0\n",
              "13_layers.SiLU_13                    -  [1028, 1745]        NaN        NaN\n",
              "14_layers.Dropout_14                 -  [1028, 1745]        NaN        NaN\n",
              "15_layers.BatchNorm1d_15        [1745]  [1028, 1745]     3490.0     1745.0\n",
              "16_layers.Linear_16       [1745, 1745]  [1028, 1745]  3046770.0  3045025.0\n",
              "17_layers.SiLU_17                    -  [1028, 1745]        NaN        NaN\n",
              "18_layers.Dropout_18                 -  [1028, 1745]        NaN        NaN\n",
              "19_layers.BatchNorm1d_19        [1745]  [1028, 1745]     3490.0     1745.0\n",
              "20_layers.Linear_20       [1745, 1745]  [1028, 1745]  3046770.0  3045025.0\n",
              "21_layers.SiLU_21                    -  [1028, 1745]        NaN        NaN\n",
              "22_layers.Dropout_22                 -  [1028, 1745]        NaN        NaN\n",
              "23_layers.BatchNorm1d_23        [1745]  [1028, 1745]     3490.0     1745.0\n",
              "24_layers.Linear_24       [1745, 1745]  [1028, 1745]  3046770.0  3045025.0\n",
              "25_layers.SiLU_25                    -  [1028, 1745]        NaN        NaN\n",
              "26_layers.Dropout_26                 -  [1028, 1745]        NaN        NaN\n",
              "27_layers.BatchNorm1d_27        [1745]  [1028, 1745]     3490.0     1745.0\n",
              "28_layers.Linear_28         [1745, 40]    [1028, 40]    69840.0    69800.0\n",
              "29_layers.LogSoftmax_29              -    [1028, 40]        NaN        NaN"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = DLHW1_MLP_modular(hparams, torch.nn.SiLU).to(device)\n",
        "frames,phoneme = next(iter(train_loader))\n",
        "# Check number of parameters of your network - Remember, you are limited to 20 million parameters for HW1 (including ensembles)\n",
        "summary(model, frames.to(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "UROGEVJevKD-"
      },
      "outputs": [],
      "source": [
        "from sched import scheduler\n",
        "\n",
        "\n",
        "criterion = torch.nn.KLDivLoss(reduction='batchmean')\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=hparams.lr) #Defining Optimizer\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, mode='min', patience=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBwunYpyugFg"
      },
      "source": [
        "# Training and Validation Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JgeNhx4x2-P"
      },
      "source": [
        "This section covers the training, and validation functions for each epoch of running your experiment with a given model architecture. The code has been provided to you, but we recommend going through the comments to understand the workflow to enable you to write these loops for future HWs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XblOHEVtKab2",
        "outputId": "e7a3c98e-8429-46a4-f348-ac4e21bd03ae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "if device == 'cuda':\n",
        "    torch.cuda.empty_cache()\n",
        "    \n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "8wjPz7DHqKcL"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer, criterion, dataloader, use_wandb:bool=True, mixed_pr:bool=False):\n",
        "\n",
        "    model.train()\n",
        "    train_loss = 0.0 #Monitoring Loss\n",
        "    \n",
        "    for iter, (mfccs, phonemes) in enumerate(dataloader):\n",
        "\n",
        "        ### Initialize Gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        ### Move Data to Device (Ideally GPU)\n",
        "        mfccs = mfccs.to(device)\n",
        "        phonemes = phonemes.to(device)\n",
        "        phonemes = F.one_hot(phonemes, num_classes=40).float()\n",
        "\n",
        "        if mixed_pr:\n",
        "            with torch.autocast(device):\n",
        "                \n",
        "                ### Forward Propagation\n",
        "                logits = model(mfccs)\n",
        "\n",
        "                ### Loss Calculation\n",
        "                loss = criterion(logits, phonemes)\n",
        "                train_loss += loss.item()\n",
        "        else:\n",
        "            ### Forward Propagation\n",
        "            logits = model(mfccs)\n",
        "\n",
        "            ### Loss Calculation\n",
        "            loss = criterion(logits, phonemes)\n",
        "            train_loss += loss.item()\n",
        "            \n",
        "        ### Backward Propagation\n",
        "        loss.backward()\n",
        "\n",
        "        ### Gradient Descent\n",
        "        optimizer.step()\n",
        "  \n",
        "    train_loss /= len(dataloader)\n",
        "    if wandb:\n",
        "        wandb.log({'train loss':train_loss})\n",
        "\n",
        "    return train_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Q5npQNFH315V"
      },
      "outputs": [],
      "source": [
        "def eval(model, dataloader, use_wandb=True):\n",
        "\n",
        "    model.eval() # set model in evaluation mode\n",
        "\n",
        "    phone_true_list = []\n",
        "    phone_pred_list = []\n",
        "    val_loss = 0.0\n",
        "\n",
        "    for i, data in enumerate(dataloader):\n",
        "\n",
        "        frames, phonemes = data\n",
        "        ### Move data to device (ideally GPU)\n",
        "        frames, phonemes = frames.to(device), phonemes.to(device)\n",
        "        with torch.inference_mode(): # makes sure that there are no gradients computed as we are not training the model now\n",
        "            ### Forward Propagation\n",
        "            logits = model(frames)\n",
        "\n",
        "        ### Get Predictions\n",
        "        predicted_phonemes = torch.argmax(logits, dim=1)\n",
        "        \n",
        "        ### Store Pred and True Labels\n",
        "        phone_pred_list.extend(predicted_phonemes.cpu().tolist())\n",
        "        phone_true_list.extend(phonemes.cpu().tolist())\n",
        "        \n",
        "        ### Convert pred to onehot\n",
        "        phonemes = F.one_hot(phonemes, num_classes=40).float()\n",
        "        predicted_phonemes = F.one_hot(predicted_phonemes, num_classes=40).float()\n",
        "\n",
        "        loss = criterion(predicted_phonemes, phonemes)\n",
        "        val_loss += loss.item()\n",
        "    \n",
        "        del frames, phonemes, logits\n",
        "        if device == 'cuda':\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    val_loss = val_loss/len(dataloader)\n",
        "\n",
        "    ### Calculate Accuracy\n",
        "    accuracy = accuracy_score(phone_pred_list, phone_true_list)\n",
        "    if use_wandb:\n",
        "        wandb.log({'validation accuracy':accuracy*100})\n",
        "        wandb.log({'validation loss':val_loss})\n",
        "\n",
        "    return val_loss, accuracy*100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMd_XxPku5qp"
      },
      "source": [
        "# Weights and Biases Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjIbhR1wwbgI"
      },
      "source": [
        "This section is to enable logging metrics and files with Weights and Biases. Please refer to wandb documentationa and recitation 0 that covers the use of weights and biases for logging, hyperparameter tuning and monitoring your runs for your homeworks. Using this tool makes it very easy to show results when submitting your code and models for homeworks, and also extremely useful for study groups to organize and run ablations under a single team in wandb. \n",
        "\n",
        "We have written code for you to make use of it out of the box, so that you start using wandb for all your HWs from the beginning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "use_wandb:bool = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "SCDYx5VEu6qI"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjbajor\u001b[0m (\u001b[33midl-group\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/jbajor/.netrc\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "wandb version 0.13.3 is available!  To upgrade, please run:\n",
              " $ pip install wandb --upgrade"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.13.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/jbajor/Dev/CMU-IDL/CMU_11-785_phoneme_prediction/wandb/run-20220929_161101-2dnbbiks</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/idl-group/hw1p2/runs/2dnbbiks\" target=\"_blank\">cyl_v12_H8_W1745_C30_noMP_1664482261</a></strong> to <a href=\"https://wandb.ai/idl-group/hw1p2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "if use_wandb:\n",
        "    from dataclasses import asdict\n",
        "    import time\n",
        "    wandb.login(key=\"c319fb8dfa7ce22e07aa0cefe0823a9752d50720\") #API Key is in your wandb account, under settings (wandb.ai/settings)\n",
        "\n",
        "    ### Create your wandb run\n",
        "    run = wandb.init(\n",
        "        name = f\"{hparams.architecture}_{int(time.time())}\", ### Wandb creates random run names if you skip this field, we recommend you give useful names\n",
        "        reinit=True, ### Allows reinitalizing runs when you re-run this cell\n",
        "        project=\"hw1p2\", ### Project should be created in your wandb account \n",
        "        config=asdict(hparams) ### Wandb Config for your run\n",
        "    )\n",
        "    ### Save your model architecture as a string with str(model) \n",
        "    model_arch = str(model)\n",
        "\n",
        "    ### Save it in a txt file \n",
        "    arch_file = open(\"model_arch.txt\", \"w\")\n",
        "    file_write = arch_file.write(model_arch)\n",
        "    arch_file.close()\n",
        "\n",
        "    ### log it in your wandb run with wandb.save()\n",
        "    wandb.save('model_arch.txt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nclx_04fu7Dd"
      },
      "source": [
        "# Experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'epoch': 23,\n",
              " 'model_state_dict': OrderedDict([('layers.0.weight',\n",
              "               tensor([[ 1.1667,  0.5752,  0.4339,  ...,  0.0970, -0.0850, -0.4561],\n",
              "                       [-0.1759,  0.1760, -0.5892,  ..., -0.4625,  0.1752, -0.3077],\n",
              "                       [ 0.2314,  0.0965, -0.0439,  ..., -0.3021, -0.0099,  0.1964],\n",
              "                       ...,\n",
              "                       [ 0.2226,  0.4204, -0.2168,  ...,  0.2165, -0.0953, -0.3430],\n",
              "                       [ 0.1174, -1.8793, -0.6521,  ..., -0.1232,  0.1457,  0.3114],\n",
              "                       [-0.3169, -0.1427, -0.2361,  ..., -0.2070,  0.3545, -0.2763]],\n",
              "                      device='cuda:0')),\n",
              "              ('layers.0.bias',\n",
              "               tensor([ -6.6531, -11.4309,  -4.7974,  ..., -15.0290, -13.9033, -16.9025],\n",
              "                      device='cuda:0')),\n",
              "              ('layers.3.weight',\n",
              "               tensor([1.3066, 1.5920, 1.4017,  ..., 1.5795, 1.3451, 1.6311], device='cuda:0')),\n",
              "              ('layers.3.bias',\n",
              "               tensor([-0.0276,  0.4191,  0.0817,  ...,  0.3012,  0.1675,  0.0982],\n",
              "                      device='cuda:0')),\n",
              "              ('layers.3.running_mean',\n",
              "               tensor([10.3594,  9.5563,  4.7292,  ...,  3.4473,  7.4744,  3.6170],\n",
              "                      device='cuda:0')),\n",
              "              ('layers.3.running_var',\n",
              "               tensor([422.4503, 451.7509, 121.3914,  ..., 117.5398, 299.5219, 118.4330],\n",
              "                      device='cuda:0')),\n",
              "              ('layers.3.num_batches_tracked',\n",
              "               tensor(844945, device='cuda:0')),\n",
              "              ('layers.4.weight',\n",
              "               tensor([[-0.2715,  0.8407, -2.6302,  ...,  1.7029, -0.7140,  1.1893],\n",
              "                       [-0.2030, -1.1448,  2.7703,  ...,  0.3067, -1.3391,  0.3863],\n",
              "                       [ 0.0273,  1.0407, -0.2248,  ...,  0.0782,  0.5812, -0.0872],\n",
              "                       ...,\n",
              "                       [ 0.6725, -0.0896, -2.9177,  ..., -2.4364, -1.0136, -2.1499],\n",
              "                       [ 0.8950, -0.2705, -0.0358,  ...,  2.1908,  0.3341, -0.8262],\n",
              "                       [-0.1720, -0.0908,  0.5785,  ...,  0.2078, -0.9047, -1.3251]],\n",
              "                      device='cuda:0')),\n",
              "              ('layers.4.bias',\n",
              "               tensor([-0.7682, -0.4155, -0.9950,  ..., -0.7481, -3.5759, -1.3311],\n",
              "                      device='cuda:0')),\n",
              "              ('layers.7.weight',\n",
              "               tensor([1.8348, 1.9039, 1.2596,  ..., 1.2461, 1.5151, 1.4266], device='cuda:0')),\n",
              "              ('layers.7.bias',\n",
              "               tensor([0.6824, 0.6603, 0.1357,  ..., 0.0820, 0.4173, 0.2457], device='cuda:0')),\n",
              "              ('layers.7.running_mean',\n",
              "               tensor([ 6.8928, 21.5936,  4.9637,  ...,  7.6650, 16.0723, 27.8168],\n",
              "                      device='cuda:0')),\n",
              "              ('layers.7.running_var',\n",
              "               tensor([ 957.4447, 2608.8909,  499.3468,  ...,  843.6401, 2324.4758,\n",
              "                       5009.9995], device='cuda:0')),\n",
              "              ('layers.7.num_batches_tracked',\n",
              "               tensor(844945, device='cuda:0')),\n",
              "              ('layers.8.weight',\n",
              "               tensor([[ 0.8175, -0.0413,  0.6627,  ..., -0.0496,  0.4942, -0.0740],\n",
              "                       [ 0.4612,  0.2818, -0.8734,  ...,  0.1611, -0.5466,  0.2035],\n",
              "                       [-1.3057, -0.1064, -0.6553,  ..., -0.0993, -2.2124, -0.3419],\n",
              "                       ...,\n",
              "                       [ 0.8555, -1.7643, -0.2568,  ..., -0.6182, -0.2469,  0.4004],\n",
              "                       [ 0.8953, -1.5805,  0.2781,  ...,  0.8853, -0.1001,  0.6760],\n",
              "                       [-1.1912,  0.3289, -1.1985,  ...,  0.2366, -0.3566,  0.1468]],\n",
              "                      device='cuda:0')),\n",
              "              ('layers.8.bias',\n",
              "               tensor([-0.5534, -1.9840, -0.7508,  ..., -0.7919, -1.2522, -0.5206],\n",
              "                      device='cuda:0')),\n",
              "              ('layers.11.weight',\n",
              "               tensor([1.4389, 1.8200, 1.8180,  ..., 1.3755, 1.4897, 1.3086], device='cuda:0')),\n",
              "              ('layers.11.bias',\n",
              "               tensor([ 0.2776,  0.4269,  0.5168,  ...,  0.1794, -0.1564,  0.2175],\n",
              "                      device='cuda:0')),\n",
              "              ('layers.11.running_mean',\n",
              "               tensor([ 7.9587,  4.3760,  3.6371,  ...,  8.3230,  7.4705, 11.1496],\n",
              "                      device='cuda:0')),\n",
              "              ('layers.11.running_var',\n",
              "               tensor([ 865.2565,  512.1359,  412.4270,  ...,  867.2385,  938.8802,\n",
              "                       1184.7050], device='cuda:0')),\n",
              "              ('layers.11.num_batches_tracked',\n",
              "               tensor(844945, device='cuda:0')),\n",
              "              ('layers.12.weight',\n",
              "               tensor([[-0.7200, -0.1633,  0.2847,  ...,  0.3988,  0.6840, -0.1678],\n",
              "                       [-0.3272,  0.6299,  0.7413,  ..., -1.0350,  0.5841,  0.1778],\n",
              "                       [ 0.0439,  0.4154, -0.9344,  ..., -0.6779,  0.5282,  0.3365],\n",
              "                       ...,\n",
              "                       [-0.3649, -0.6985,  0.6071,  ..., -0.6451,  0.3353, -1.7011],\n",
              "                       [-0.8219, -0.5128,  1.1433,  ...,  1.8204,  1.4626,  1.7387],\n",
              "                       [-0.2220, -1.1564, -0.1692,  ..., -0.5508, -1.9452, -0.1787]],\n",
              "                      device='cuda:0')),\n",
              "              ('layers.12.bias',\n",
              "               tensor([-1.2469, -0.2064, -1.2790,  ..., -1.1154, -1.9192, -0.6421],\n",
              "                      device='cuda:0')),\n",
              "              ('layers.15.weight',\n",
              "               tensor([1.7108, 1.4714, 1.7942,  ..., 1.6284, 1.4200, 1.5203], device='cuda:0')),\n",
              "              ('layers.15.bias',\n",
              "               tensor([0.3843, 0.4115, 0.3709,  ..., 0.2991, 0.2826, 0.2657], device='cuda:0')),\n",
              "              ('layers.15.running_mean',\n",
              "               tensor([13.9499, 10.0709,  8.6866,  ...,  6.7756,  7.8185, 11.7044],\n",
              "                      device='cuda:0')),\n",
              "              ('layers.15.running_var',\n",
              "               tensor([1705.5232, 1310.1655, 1135.7916,  ...,  698.1884, 1019.4384,\n",
              "                       1338.5974], device='cuda:0')),\n",
              "              ('layers.15.num_batches_tracked',\n",
              "               tensor(844945, device='cuda:0')),\n",
              "              ('layers.16.weight',\n",
              "               tensor([[ 0.7504, -0.4423,  0.8636,  ...,  1.4851,  1.0081, -0.3714],\n",
              "                       [-1.4882,  1.2571, -0.4647,  ..., -0.5973, -0.3149, -0.9438],\n",
              "                       [-0.8330, -1.3787,  0.3958,  ...,  0.9240,  1.3960,  0.2987],\n",
              "                       ...,\n",
              "                       [ 0.1297,  1.5987, -0.1333,  ...,  1.3312, -0.8807, -0.4897],\n",
              "                       [-1.4566, -0.3443,  0.4318,  ...,  0.3348,  1.5855, -0.1413],\n",
              "                       [-0.4280, -0.8576, -0.4782,  ..., -0.6527, -1.7816, -1.2576]],\n",
              "                      device='cuda:0')),\n",
              "              ('layers.16.bias',\n",
              "               tensor([ 0.3686, -0.9774, -2.6984,  ..., -1.6952, -1.7929, -1.1353],\n",
              "                      device='cuda:0')),\n",
              "              ('layers.19.weight',\n",
              "               tensor([1.4360, 1.4003, 1.3815,  ..., 1.4576, 1.4539, 1.3804], device='cuda:0')),\n",
              "              ('layers.19.bias',\n",
              "               tensor([ 0.2646,  0.5128, -0.0259,  ...,  0.4315,  0.3287,  0.0404],\n",
              "                      device='cuda:0')),\n",
              "              ('layers.19.running_mean',\n",
              "               tensor([ 6.1176,  9.0791,  8.2113,  ...,  4.9564,  9.3670, 10.4196],\n",
              "                      device='cuda:0')),\n",
              "              ('layers.19.running_var',\n",
              "               tensor([ 609.2648, 1103.3502,  912.4017,  ...,  593.6142, 1226.9281,\n",
              "                       1352.1741], device='cuda:0')),\n",
              "              ('layers.19.num_batches_tracked',\n",
              "               tensor(844945, device='cuda:0')),\n",
              "              ('layers.20.weight',\n",
              "               tensor([[-0.4466,  0.8769, -3.0215,  ..., -0.3001, -3.5204,  1.8356],\n",
              "                       [-1.1175,  0.4798,  1.9619,  ..., -1.0195, -0.8200, -1.2020],\n",
              "                       [ 0.2301,  0.8643, -0.0340,  ..., -0.5506, -1.0546, -0.5307],\n",
              "                       ...,\n",
              "                       [ 0.4035, -0.1421, -1.0302,  ..., -1.0756, -0.8926, -0.3488],\n",
              "                       [ 0.5371, -0.7793, -0.0212,  ..., -0.0719, -0.1799, -1.3442],\n",
              "                       [-1.4663, -0.2796, -0.1143,  ...,  0.2557,  0.3973,  1.1510]],\n",
              "                      device='cuda:0')),\n",
              "              ('layers.20.bias',\n",
              "               tensor([ 0.3872, -1.0920, -0.9608,  ...,  1.3309, -0.5074, -1.3376],\n",
              "                      device='cuda:0')),\n",
              "              ('layers.23.weight',\n",
              "               tensor([1.1674, 1.1313, 1.4725,  ..., 1.7124, 1.5409, 1.6671], device='cuda:0')),\n",
              "              ('layers.23.bias',\n",
              "               tensor([0.0397, 0.1870, 0.4356,  ..., 0.5663, 0.2491, 0.4224], device='cuda:0')),\n",
              "              ('layers.23.running_mean',\n",
              "               tensor([12.6638, 11.1660, 16.6768,  ..., 23.7818,  6.7498,  9.9887],\n",
              "                      device='cuda:0')),\n",
              "              ('layers.23.running_var',\n",
              "               tensor([1487.4984, 1576.1234, 2037.5732,  ..., 3242.4089,  647.7998,\n",
              "                       1902.4570], device='cuda:0')),\n",
              "              ('layers.23.num_batches_tracked',\n",
              "               tensor(844945, device='cuda:0')),\n",
              "              ('layers.24.weight',\n",
              "               tensor([[-1.7645,  0.5759,  0.0242,  ...,  0.5693, -0.6820, -1.4987],\n",
              "                       [ 1.8757, -2.2754,  0.4457,  ..., -0.3324, -1.0162,  0.4287],\n",
              "                       [ 0.6940,  0.1622, -0.4608,  ..., -0.9541, -1.2730,  0.5898],\n",
              "                       ...,\n",
              "                       [ 0.7898, -1.1604,  0.0553,  ...,  0.5053, -0.9395, -0.4712],\n",
              "                       [-1.1140, -1.1679,  0.6257,  ..., -2.3382,  0.2115,  0.2332],\n",
              "                       [ 1.2932, -1.0699, -0.6150,  ..., -0.2432,  0.4487,  0.0871]],\n",
              "                      device='cuda:0')),\n",
              "              ('layers.24.bias',\n",
              "               tensor([ 0.8791,  0.8043, -0.6170,  ...,  0.7062,  0.0536, -0.1391],\n",
              "                      device='cuda:0')),\n",
              "              ('layers.27.weight',\n",
              "               tensor([0.1113, 0.0783, 0.2773,  ..., 0.1095, 0.2039, 0.3253], device='cuda:0')),\n",
              "              ('layers.27.bias',\n",
              "               tensor([0.0397, 0.0140, 0.0461,  ..., 0.0361, 0.0313, 0.0377], device='cuda:0')),\n",
              "              ('layers.27.running_mean',\n",
              "               tensor([47.0776, 27.5867, 37.5282,  ..., 56.9047, 44.5869, 33.1784],\n",
              "                      device='cuda:0')),\n",
              "              ('layers.27.running_var',\n",
              "               tensor([ 8632.4014,  2902.9719, 34469.1289,  ..., 11255.9941, 48868.0625,\n",
              "                       25544.7773], device='cuda:0')),\n",
              "              ('layers.27.num_batches_tracked',\n",
              "               tensor(844945, device='cuda:0')),\n",
              "              ('layers.28.weight',\n",
              "               tensor([[ 0.0639, -0.3603, -0.0578,  ...,  0.0689, -0.4825,  0.0127],\n",
              "                       [ 0.0299, -0.0351, -0.6744,  ...,  0.0150, -0.3388, -0.0529],\n",
              "                       [-0.2969,  0.0727, -0.6644,  ..., -0.0330, -0.4333,  0.1044],\n",
              "                       ...,\n",
              "                       [-0.1104,  0.0197, -0.0158,  ...,  0.0061, -0.0545, -0.2298],\n",
              "                       [-0.1019,  0.0681, -0.0562,  ...,  0.1857, -0.4666,  0.0956],\n",
              "                       [-0.1430,  0.1377,  0.3420,  ...,  0.0207,  0.5434, -0.5986]],\n",
              "                      device='cuda:0')),\n",
              "              ('layers.28.bias',\n",
              "               tensor([ 0.2038, -0.0450,  0.1571,  1.8497, -0.5383, -1.0716, -0.4008, -0.5099,\n",
              "                       -1.0022,  0.7870, -0.4119,  0.0531, -0.1054, -0.5088, -0.4666, -0.9396,\n",
              "                        0.0851,  0.8113,  0.2472, -0.8637, -0.0279,  0.3694, -0.4631,  0.6277,\n",
              "                       -0.9517, -0.0843, -2.1808, -0.5650,  0.2796,  0.0907, -1.0355,  1.3524,\n",
              "                       -0.7426, -1.3611, -0.5246, -0.1585, -0.3262, -0.8372, -0.0904, -2.3869],\n",
              "                      device='cuda:0'))]),\n",
              " 'optimizer_state_dict': {'state': {0: {'step': tensor(844944.),\n",
              "    'exp_avg': tensor([[-4.7497e-07,  2.3392e-06, -4.1106e-06,  ...,  4.2558e-06,\n",
              "              1.0322e-05, -2.8685e-06],\n",
              "            [ 2.2634e-06,  1.2821e-07, -8.8717e-06,  ...,  6.7305e-06,\n",
              "              5.0654e-06,  1.1425e-06],\n",
              "            [-1.7440e-05,  4.0227e-06,  1.2491e-05,  ...,  1.9474e-05,\n",
              "              1.7362e-05,  1.7014e-05],\n",
              "            ...,\n",
              "            [-5.3366e-06, -2.7011e-07, -2.9682e-06,  ..., -6.3625e-06,\n",
              "             -1.5510e-07, -3.8432e-06],\n",
              "            [-2.7303e-06,  4.8431e-07,  3.2913e-06,  ...,  8.0390e-07,\n",
              "              6.7642e-06,  3.0382e-06],\n",
              "            [ 5.7030e-06, -2.3085e-05,  8.0799e-06,  ..., -2.9238e-06,\n",
              "             -7.1850e-06, -1.3883e-05]], device='cuda:0'),\n",
              "    'exp_avg_sq': tensor([[2.8807e-10, 3.4977e-10, 3.4000e-10,  ..., 3.2788e-10, 3.3216e-10,\n",
              "             3.2914e-10],\n",
              "            [3.0954e-10, 3.7354e-10, 3.5314e-10,  ..., 3.5738e-10, 3.2696e-10,\n",
              "             3.4330e-10],\n",
              "            [1.1433e-09, 1.2867e-09, 1.3684e-09,  ..., 1.2878e-09, 1.3526e-09,\n",
              "             1.2500e-09],\n",
              "            ...,\n",
              "            [7.9459e-10, 9.0762e-10, 9.5228e-10,  ..., 8.9541e-10, 9.1320e-10,\n",
              "             9.2206e-10],\n",
              "            [3.4331e-10, 4.5521e-10, 4.5223e-10,  ..., 4.1251e-10, 3.9795e-10,\n",
              "             3.9405e-10],\n",
              "            [1.1258e-09, 1.3072e-09, 1.2532e-09,  ..., 1.2080e-09, 1.2478e-09,\n",
              "             1.2870e-09]], device='cuda:0')},\n",
              "   1: {'step': tensor(844944.),\n",
              "    'exp_avg': tensor([-3.6040e-07,  1.7613e-06,  4.6766e-06,  ..., -1.8947e-06,\n",
              "            -1.8983e-07,  1.0625e-05], device='cuda:0'),\n",
              "    'exp_avg_sq': tensor([1.1937e-10, 1.3761e-10, 4.9783e-10,  ..., 3.8945e-10, 1.5068e-10,\n",
              "            5.0534e-10], device='cuda:0')},\n",
              "   2: {'step': tensor(844944.),\n",
              "    'exp_avg': tensor([ 6.9791e-05, -3.0542e-05, -6.9385e-05,  ...,  3.7165e-05,\n",
              "            -3.2387e-05,  1.4181e-04], device='cuda:0'),\n",
              "    'exp_avg_sq': tensor([1.1120e-07, 1.0475e-07, 1.3016e-07,  ..., 1.2055e-07, 1.0784e-07,\n",
              "            1.0956e-07], device='cuda:0')},\n",
              "   3: {'step': tensor(844944.),\n",
              "    'exp_avg': tensor([-5.4275e-05,  2.7372e-05,  5.1263e-05,  ...,  3.1991e-05,\n",
              "             1.1255e-04,  6.2218e-05], device='cuda:0'),\n",
              "    'exp_avg_sq': tensor([4.4418e-08, 4.6880e-08, 4.6134e-08,  ..., 4.9656e-08, 5.0699e-08,\n",
              "            5.3804e-08], device='cuda:0')},\n",
              "   4: {'step': tensor(844944.),\n",
              "    'exp_avg': tensor([[-1.6306e-06, -2.4135e-06,  2.7548e-06,  ..., -8.1657e-07,\n",
              "             -5.5755e-07, -2.3165e-06],\n",
              "            [-5.8210e-07,  1.7398e-06,  6.4115e-07,  ..., -1.7810e-06,\n",
              "             -6.0779e-06, -4.0420e-06],\n",
              "            [-1.9609e-06,  1.5399e-06, -4.8083e-06,  ..., -3.0189e-06,\n",
              "             -1.7065e-06,  3.1553e-06],\n",
              "            ...,\n",
              "            [-4.3707e-07, -5.2318e-06,  2.0913e-07,  ..., -3.2674e-06,\n",
              "             -1.6066e-06,  8.7980e-08],\n",
              "            [ 1.3296e-06,  2.6255e-06, -8.7692e-07,  ..., -3.9675e-07,\n",
              "             -2.6683e-06, -1.2075e-06],\n",
              "            [ 8.4393e-07, -4.1294e-06, -3.3015e-06,  ..., -1.0187e-06,\n",
              "             -3.2494e-07,  7.4107e-07]], device='cuda:0'),\n",
              "    'exp_avg_sq': tensor([[1.4171e-10, 2.3913e-10, 1.2750e-10,  ..., 2.7676e-10, 1.4245e-10,\n",
              "             3.1492e-10],\n",
              "            [8.0207e-11, 7.4588e-11, 5.7093e-11,  ..., 7.1062e-11, 1.2798e-10,\n",
              "             1.7261e-10],\n",
              "            [8.1185e-11, 1.7237e-10, 1.4970e-10,  ..., 1.8935e-10, 1.1326e-10,\n",
              "             1.6547e-10],\n",
              "            ...,\n",
              "            [9.5508e-11, 1.9541e-10, 8.6555e-11,  ..., 6.8060e-11, 9.4482e-11,\n",
              "             9.5893e-11],\n",
              "            [5.3369e-11, 5.7372e-11, 7.9616e-11,  ..., 1.3350e-10, 7.3589e-11,\n",
              "             7.8183e-11],\n",
              "            [4.8451e-11, 6.6686e-11, 9.6703e-11,  ..., 7.5008e-11, 3.5065e-11,\n",
              "             7.0607e-11]], device='cuda:0')},\n",
              "   5: {'step': tensor(844944.),\n",
              "    'exp_avg': tensor([ 6.8658e-07, -1.1347e-06, -1.4974e-06,  ..., -6.7980e-07,\n",
              "            -1.0166e-06, -1.6246e-06], device='cuda:0'),\n",
              "    'exp_avg_sq': tensor([4.6885e-11, 1.8269e-11, 2.4144e-11,  ..., 2.1183e-11, 1.1694e-11,\n",
              "            1.5244e-11], device='cuda:0')},\n",
              "   6: {'step': tensor(844944.),\n",
              "    'exp_avg': tensor([ 1.0086e-04, -5.8395e-05, -6.8280e-05,  ...,  1.1738e-04,\n",
              "            -5.0778e-05, -3.8961e-05], device='cuda:0'),\n",
              "    'exp_avg_sq': tensor([8.1985e-08, 5.4799e-08, 1.1599e-07,  ..., 1.1712e-07, 6.7656e-08,\n",
              "            9.0454e-08], device='cuda:0')},\n",
              "   7: {'step': tensor(844944.),\n",
              "    'exp_avg': tensor([ 2.3887e-05, -1.3391e-04, -1.1071e-05,  ...,  6.7351e-05,\n",
              "             3.0626e-05,  2.1380e-05], device='cuda:0'),\n",
              "    'exp_avg_sq': tensor([5.9846e-08, 5.4301e-08, 3.4646e-08,  ..., 3.1691e-08, 3.3311e-08,\n",
              "            6.9566e-08], device='cuda:0')},\n",
              "   8: {'step': tensor(844944.),\n",
              "    'exp_avg': tensor([[ 6.1656e-07, -9.5444e-07,  5.0094e-06,  ..., -1.7616e-06,\n",
              "              4.4708e-06,  6.0803e-07],\n",
              "            [-2.9058e-06, -3.2412e-07,  5.0960e-07,  ..., -1.4388e-06,\n",
              "             -2.0565e-07, -1.0192e-07],\n",
              "            [-1.5206e-06,  4.2380e-06, -1.2802e-06,  ...,  1.8843e-06,\n",
              "              1.4658e-07,  3.6860e-06],\n",
              "            ...,\n",
              "            [-1.3364e-06, -2.4635e-07, -1.5862e-06,  ..., -1.0694e-06,\n",
              "              5.5649e-08, -1.6327e-06],\n",
              "            [-1.7798e-07, -3.7554e-07, -2.4006e-06,  ..., -1.9853e-06,\n",
              "             -3.5638e-06,  1.8676e-06],\n",
              "            [ 1.1036e-06, -2.0217e-06,  1.4524e-06,  ...,  2.1397e-06,\n",
              "             -1.1476e-06,  2.9696e-06]], device='cuda:0'),\n",
              "    'exp_avg_sq': tensor([[1.8939e-10, 7.0404e-11, 8.9441e-11,  ..., 6.7134e-11, 9.3551e-11,\n",
              "             9.4978e-11],\n",
              "            [2.4850e-10, 7.9895e-11, 4.5783e-11,  ..., 9.6347e-11, 8.5609e-11,\n",
              "             1.3072e-10],\n",
              "            [1.3380e-10, 2.1031e-10, 1.0890e-10,  ..., 1.4703e-10, 1.1427e-11,\n",
              "             7.8217e-11],\n",
              "            ...,\n",
              "            [2.9678e-10, 4.0725e-12, 6.6243e-11,  ..., 3.8627e-11, 4.7436e-11,\n",
              "             1.7649e-10],\n",
              "            [3.3015e-10, 8.2895e-12, 9.3101e-11,  ..., 8.6253e-11, 7.8082e-11,\n",
              "             1.7889e-10],\n",
              "            [1.0239e-10, 8.6394e-11, 4.6366e-11,  ..., 4.7371e-11, 6.4539e-11,\n",
              "             8.2177e-11]], device='cuda:0')},\n",
              "   9: {'step': tensor(844944.),\n",
              "    'exp_avg': tensor([ 1.5822e-06, -1.3967e-06, -4.6263e-07,  ...,  1.5424e-07,\n",
              "             2.0076e-07,  7.9156e-07], device='cuda:0'),\n",
              "    'exp_avg_sq': tensor([1.6148e-11, 2.2061e-11, 2.5470e-11,  ..., 1.7983e-11, 1.7775e-11,\n",
              "            1.4697e-11], device='cuda:0')},\n",
              "   10: {'step': tensor(844944.),\n",
              "    'exp_avg': tensor([ 1.5368e-05, -1.0366e-06, -5.6349e-06,  ..., -9.8406e-07,\n",
              "            -2.5006e-05,  5.2369e-06], device='cuda:0'),\n",
              "    'exp_avg_sq': tensor([6.3373e-08, 4.2228e-08, 4.0279e-08,  ..., 7.4344e-08, 7.1692e-08,\n",
              "            6.5656e-08], device='cuda:0')},\n",
              "   11: {'step': tensor(844944.),\n",
              "    'exp_avg': tensor([-1.2198e-05,  6.2937e-05, -9.5187e-05,  ...,  1.4032e-05,\n",
              "            -2.2230e-05,  3.4471e-05], device='cuda:0'),\n",
              "    'exp_avg_sq': tensor([2.3825e-08, 2.4986e-08, 3.2992e-08,  ..., 2.9702e-08, 2.7742e-08,\n",
              "            2.4806e-08], device='cuda:0')},\n",
              "   12: {'step': tensor(844944.),\n",
              "    'exp_avg': tensor([[-5.2098e-07,  2.7578e-06, -3.5356e-07,  ...,  2.3543e-06,\n",
              "              2.0459e-06,  2.3481e-06],\n",
              "            [ 1.3003e-06, -1.8094e-06,  1.6206e-07,  ..., -1.6772e-07,\n",
              "              2.2955e-06,  2.0725e-08],\n",
              "            [-2.1276e-06,  1.0187e-06, -3.9242e-07,  ..., -2.2139e-06,\n",
              "              3.2106e-06, -3.5950e-07],\n",
              "            ...,\n",
              "            [-1.0359e-06, -2.4870e-06,  5.9194e-07,  ...,  1.4797e-06,\n",
              "              3.0154e-08, -1.0536e-06],\n",
              "            [ 1.2873e-06, -2.1854e-06,  1.2191e-06,  ..., -2.5408e-06,\n",
              "             -2.8202e-06, -1.1087e-06],\n",
              "            [-1.1360e-06,  4.4670e-07,  6.4688e-07,  ...,  1.5055e-07,\n",
              "              8.7323e-07,  9.5678e-08]], device='cuda:0'),\n",
              "    'exp_avg_sq': tensor([[4.6856e-11, 7.4675e-11, 4.6935e-11,  ..., 8.0291e-11, 1.1257e-10,\n",
              "             5.5674e-11],\n",
              "            [4.3272e-11, 5.9006e-11, 4.4514e-11,  ..., 1.6125e-11, 8.8850e-11,\n",
              "             6.3163e-11],\n",
              "            [6.6629e-11, 4.9909e-11, 6.0911e-11,  ..., 7.8797e-11, 1.1370e-10,\n",
              "             4.5804e-11],\n",
              "            ...,\n",
              "            [3.3846e-11, 3.7324e-11, 1.7709e-10,  ..., 3.2468e-11, 4.3176e-11,\n",
              "             1.9731e-11],\n",
              "            [3.9272e-11, 4.6194e-11, 6.6479e-11,  ..., 7.0882e-11, 6.2468e-11,\n",
              "             3.9598e-11],\n",
              "            [6.4360e-11, 2.4517e-11, 8.0038e-11,  ..., 5.0611e-11, 2.3922e-11,\n",
              "             4.0193e-11]], device='cuda:0')},\n",
              "   13: {'step': tensor(844944.),\n",
              "    'exp_avg': tensor([-3.0411e-07, -1.3250e-06, -5.5973e-07,  ...,  1.9283e-07,\n",
              "            -2.6894e-07,  5.5269e-07], device='cuda:0'),\n",
              "    'exp_avg_sq': tensor([1.1257e-11, 1.0296e-11, 1.1138e-11,  ..., 1.1376e-11, 9.4442e-12,\n",
              "            9.6422e-12], device='cuda:0')},\n",
              "   14: {'step': tensor(844944.),\n",
              "    'exp_avg': tensor([-5.2655e-05, -4.9769e-05,  4.6346e-05,  ...,  1.0393e-04,\n",
              "            -4.1517e-05, -4.1093e-05], device='cuda:0'),\n",
              "    'exp_avg_sq': tensor([3.4289e-08, 3.9986e-08, 2.9428e-08,  ..., 3.1909e-08, 3.8906e-08,\n",
              "            3.3534e-08], device='cuda:0')},\n",
              "   15: {'step': tensor(844944.),\n",
              "    'exp_avg': tensor([ 1.7129e-05,  4.5825e-06, -2.0964e-05,  ..., -2.3112e-05,\n",
              "            -2.4874e-05,  8.4745e-05], device='cuda:0'),\n",
              "    'exp_avg_sq': tensor([2.0343e-08, 1.7662e-08, 1.8381e-08,  ..., 1.5545e-08, 1.7777e-08,\n",
              "            1.6408e-08], device='cuda:0')},\n",
              "   16: {'step': tensor(844944.),\n",
              "    'exp_avg': tensor([[-9.3212e-07,  3.2052e-07,  1.3240e-06,  ..., -3.4948e-07,\n",
              "              1.9820e-06,  2.4553e-07],\n",
              "            [ 3.1717e-06, -1.4662e-07,  1.0146e-06,  ..., -9.0684e-07,\n",
              "              1.4306e-06, -1.3238e-08],\n",
              "            [ 2.0310e-07,  2.0209e-07, -2.9177e-06,  ...,  3.8332e-06,\n",
              "             -1.5044e-06,  7.7097e-07],\n",
              "            ...,\n",
              "            [ 2.1196e-06, -7.5923e-07,  3.6498e-06,  ...,  7.1081e-07,\n",
              "              1.7342e-07, -7.3385e-07],\n",
              "            [ 3.0941e-07,  2.5803e-07,  1.1254e-06,  ..., -2.2788e-06,\n",
              "              8.4355e-07,  9.8206e-07],\n",
              "            [ 1.1207e-06,  5.7583e-08, -2.6335e-07,  ..., -1.1138e-06,\n",
              "              9.5553e-07,  1.7237e-06]], device='cuda:0'),\n",
              "    'exp_avg_sq': tensor([[8.7805e-11, 1.2914e-11, 6.0815e-11,  ..., 4.2381e-11, 6.4674e-11,\n",
              "             2.6259e-11],\n",
              "            [3.7785e-11, 2.4290e-11, 5.1933e-11,  ..., 2.3587e-11, 4.1094e-11,\n",
              "             1.7130e-11],\n",
              "            [2.3252e-11, 1.8216e-11, 4.7359e-11,  ..., 7.9473e-11, 5.8729e-11,\n",
              "             5.0102e-11],\n",
              "            ...,\n",
              "            [7.9553e-11, 5.8723e-11, 8.3741e-11,  ..., 3.7698e-11, 4.3081e-11,\n",
              "             2.2962e-11],\n",
              "            [1.1285e-11, 2.1527e-11, 4.6847e-11,  ..., 5.3688e-11, 3.3474e-11,\n",
              "             2.6378e-11],\n",
              "            [1.8638e-11, 2.8737e-11, 2.0903e-11,  ..., 2.2676e-11, 8.2876e-12,\n",
              "             3.5389e-11]], device='cuda:0')},\n",
              "   17: {'step': tensor(844944.),\n",
              "    'exp_avg': tensor([ 3.7580e-07,  1.6333e-07,  6.2486e-07,  ...,  5.1324e-07,\n",
              "            -7.8651e-07, -5.3205e-07], device='cuda:0'),\n",
              "    'exp_avg_sq': tensor([9.4648e-12, 7.0267e-12, 8.9626e-12,  ..., 1.0472e-11, 6.4697e-12,\n",
              "            6.2483e-12], device='cuda:0')},\n",
              "   18: {'step': tensor(844944.),\n",
              "    'exp_avg': tensor([ 1.6821e-05, -1.7643e-05,  8.9451e-05,  ...,  3.0200e-06,\n",
              "            -1.5405e-05, -2.2223e-05], device='cuda:0'),\n",
              "    'exp_avg_sq': tensor([2.7199e-08, 2.7450e-08, 3.2436e-08,  ..., 2.7892e-08, 1.9802e-08,\n",
              "            2.3086e-08], device='cuda:0')},\n",
              "   19: {'step': tensor(844944.),\n",
              "    'exp_avg': tensor([ 1.1631e-05, -1.2068e-05,  3.2610e-05,  ...,  2.3616e-05,\n",
              "            -2.6247e-05, -1.8609e-05], device='cuda:0'),\n",
              "    'exp_avg_sq': tensor([1.0485e-08, 1.4691e-08, 1.1834e-08,  ..., 1.2717e-08, 1.2459e-08,\n",
              "            1.0466e-08], device='cuda:0')},\n",
              "   20: {'step': tensor(844944.),\n",
              "    'exp_avg': tensor([[-7.2618e-07, -9.8680e-08, -7.3165e-07,  ...,  1.6138e-07,\n",
              "              7.2256e-07, -7.4454e-07],\n",
              "            [-9.7881e-07,  7.2117e-07,  1.1203e-06,  ...,  7.2704e-07,\n",
              "             -1.2927e-06, -1.3176e-06],\n",
              "            [-2.7373e-07, -1.3720e-06,  5.1197e-07,  ..., -2.3286e-07,\n",
              "              9.1036e-08,  5.6924e-07],\n",
              "            ...,\n",
              "            [ 4.2479e-07,  1.7744e-06, -4.1148e-07,  ...,  3.3185e-07,\n",
              "              1.0190e-08, -1.4770e-06],\n",
              "            [ 3.6663e-07,  1.2610e-06,  1.3385e-06,  ..., -1.0043e-06,\n",
              "             -2.9743e-07,  6.9973e-07],\n",
              "            [-5.8717e-08,  9.9940e-07,  8.3471e-07,  ..., -1.1210e-06,\n",
              "             -8.2786e-07, -2.5975e-07]], device='cuda:0'),\n",
              "    'exp_avg_sq': tensor([[1.8722e-11, 2.1073e-11, 4.1615e-12,  ..., 1.3158e-11, 5.0067e-12,\n",
              "             1.1975e-11],\n",
              "            [6.5714e-12, 2.4615e-11, 1.4427e-11,  ..., 9.4184e-12, 1.1078e-11,\n",
              "             9.4992e-12],\n",
              "            [1.6910e-11, 1.9286e-11, 9.3881e-12,  ..., 3.1376e-11, 3.1416e-12,\n",
              "             8.9017e-12],\n",
              "            ...,\n",
              "            [1.8730e-11, 2.3121e-11, 1.1826e-11,  ..., 1.2863e-11, 1.0899e-11,\n",
              "             1.5745e-11],\n",
              "            [1.8380e-11, 6.5492e-12, 3.5745e-11,  ..., 3.2973e-11, 1.4052e-11,\n",
              "             1.1919e-11],\n",
              "            [2.6471e-12, 1.8518e-11, 2.0057e-11,  ..., 2.6578e-11, 1.0632e-11,\n",
              "             1.8274e-11]], device='cuda:0')},\n",
              "   21: {'step': tensor(844944.),\n",
              "    'exp_avg': tensor([ 2.1657e-07,  5.9777e-08,  3.7993e-07,  ..., -1.8925e-07,\n",
              "             1.8457e-08,  9.0792e-08], device='cuda:0'),\n",
              "    'exp_avg_sq': tensor([3.4957e-12, 2.8221e-12, 3.1596e-12,  ..., 3.9135e-12, 5.6364e-12,\n",
              "            3.7065e-12], device='cuda:0')},\n",
              "   22: {'step': tensor(844944.),\n",
              "    'exp_avg': tensor([-3.1327e-05,  8.2370e-08,  1.7975e-05,  ...,  8.8137e-06,\n",
              "             1.8972e-05, -2.9866e-06], device='cuda:0'),\n",
              "    'exp_avg_sq': tensor([1.9889e-08, 1.9155e-08, 1.3630e-08,  ..., 1.3814e-08, 1.4106e-08,\n",
              "            8.9730e-09], device='cuda:0')},\n",
              "   23: {'step': tensor(844944.),\n",
              "    'exp_avg': tensor([ 1.0534e-05, -1.8905e-05, -4.5429e-05,  ...,  3.8618e-05,\n",
              "             2.6078e-05,  4.1274e-06], device='cuda:0'),\n",
              "    'exp_avg_sq': tensor([2.0509e-08, 1.7051e-08, 2.2515e-08,  ..., 2.7516e-08, 1.6345e-08,\n",
              "            1.5866e-08], device='cuda:0')},\n",
              "   24: {'step': tensor(844944.),\n",
              "    'exp_avg': tensor([[ 5.0347e-07, -9.3973e-08,  1.6098e-06,  ...,  3.4773e-07,\n",
              "              5.0481e-07, -4.5426e-07],\n",
              "            [ 8.8639e-07, -7.9973e-07, -1.5893e-07,  ..., -2.8447e-07,\n",
              "              2.5702e-07, -1.1806e-07],\n",
              "            [ 5.6142e-07,  6.8830e-07,  2.0924e-06,  ...,  5.8556e-09,\n",
              "             -9.5164e-07,  9.9796e-07],\n",
              "            ...,\n",
              "            [ 6.3598e-07,  4.6764e-07,  6.3420e-07,  ..., -8.6539e-07,\n",
              "              1.1374e-06, -2.0060e-07],\n",
              "            [-2.8022e-09,  6.6823e-07,  2.3064e-08,  ..., -2.0454e-07,\n",
              "              8.5914e-10, -2.7402e-08],\n",
              "            [-9.9129e-07,  6.8548e-07, -1.9067e-06,  ..., -2.5220e-07,\n",
              "              1.6374e-07,  3.7613e-07]], device='cuda:0'),\n",
              "    'exp_avg_sq': tensor([[4.7034e-12, 8.2689e-12, 6.8102e-12,  ..., 9.5753e-12, 7.7397e-12,\n",
              "             2.9948e-12],\n",
              "            [1.0237e-11, 6.0762e-12, 9.6405e-12,  ..., 1.3745e-11, 5.2298e-12,\n",
              "             5.3747e-12],\n",
              "            [1.5034e-11, 5.6495e-12, 2.5423e-11,  ..., 9.6195e-12, 1.0535e-11,\n",
              "             1.6240e-11],\n",
              "            ...,\n",
              "            [7.3848e-12, 7.1804e-12, 5.4441e-12,  ..., 9.4761e-12, 3.9178e-12,\n",
              "             4.4025e-12],\n",
              "            [3.8626e-12, 4.9779e-12, 1.4651e-12,  ..., 3.7247e-12, 3.1341e-12,\n",
              "             3.1634e-12],\n",
              "            [8.6593e-12, 9.2426e-12, 1.2214e-11,  ..., 1.0205e-11, 7.3102e-12,\n",
              "             6.8387e-12]], device='cuda:0')},\n",
              "   25: {'step': tensor(844944.),\n",
              "    'exp_avg': tensor([-2.2203e-07, -2.7532e-07,  6.0913e-07,  ..., -1.6747e-07,\n",
              "            -1.7815e-07, -1.1228e-06], device='cuda:0'),\n",
              "    'exp_avg_sq': tensor([3.6661e-12, 3.4815e-12, 7.0145e-12,  ..., 2.6921e-12, 2.8942e-12,\n",
              "            7.5121e-12], device='cuda:0')},\n",
              "   26: {'step': tensor(844944.),\n",
              "    'exp_avg': tensor([-4.8323e-04, -7.7245e-04, -7.5039e-05,  ...,  5.4942e-04,\n",
              "             6.6448e-05,  5.2760e-05], device='cuda:0'),\n",
              "    'exp_avg_sq': tensor([3.4361e-06, 5.9767e-06, 5.0285e-07,  ..., 3.0466e-06, 5.6752e-07,\n",
              "            7.2002e-07], device='cuda:0')},\n",
              "   27: {'step': tensor(844944.),\n",
              "    'exp_avg': tensor([-0.0004,  0.0018,  0.0006,  ..., -0.0010, -0.0006, -0.0016],\n",
              "           device='cuda:0'),\n",
              "    'exp_avg_sq': tensor([1.3250e-05, 1.9118e-05, 1.1053e-05,  ..., 1.2637e-05, 1.4815e-05,\n",
              "            2.0826e-05], device='cuda:0')},\n",
              "   28: {'step': tensor(844944.),\n",
              "    'exp_avg': tensor([[-1.8172e-05, -4.8427e-05,  4.3754e-05,  ...,  1.9004e-05,\n",
              "             -1.0036e-05, -5.3728e-05],\n",
              "            [-1.4343e-05, -2.5351e-05, -2.5788e-05,  ...,  1.3240e-06,\n",
              "              9.1224e-06,  1.1372e-04],\n",
              "            [ 4.0740e-05, -4.3506e-05,  5.6718e-06,  ..., -3.9668e-05,\n",
              "             -6.5340e-06, -5.7713e-06],\n",
              "            ...,\n",
              "            [ 7.1807e-07,  2.8481e-05, -8.9398e-06,  ...,  1.1419e-05,\n",
              "              2.5133e-05,  1.6070e-05],\n",
              "            [ 3.9245e-06, -4.4510e-05, -3.9147e-06,  ..., -1.0939e-05,\n",
              "              1.9261e-05,  1.4819e-05],\n",
              "            [ 1.2372e-08, -4.5939e-06,  3.9175e-07,  ..., -6.2727e-06,\n",
              "              8.9133e-07,  5.2469e-07]], device='cuda:0'),\n",
              "    'exp_avg_sq': tensor([[1.0232e-07, 1.0678e-08, 2.6577e-08,  ..., 7.5401e-08, 3.3356e-09,\n",
              "             4.0216e-08],\n",
              "            [2.0133e-08, 4.3047e-08, 5.3873e-09,  ..., 1.9192e-08, 1.8901e-09,\n",
              "             3.8170e-08],\n",
              "            [9.1943e-09, 5.8599e-08, 1.3791e-08,  ..., 2.0895e-08, 2.9688e-09,\n",
              "             3.0982e-08],\n",
              "            ...,\n",
              "            [7.5887e-09, 1.4545e-08, 2.0357e-09,  ..., 6.1854e-09, 1.1026e-08,\n",
              "             3.5230e-09],\n",
              "            [1.0343e-08, 8.0672e-08, 1.6634e-08,  ..., 4.6898e-08, 2.3759e-09,\n",
              "             2.4264e-08],\n",
              "            [2.5788e-10, 3.3069e-09, 1.8094e-09,  ..., 1.3787e-09, 3.0295e-10,\n",
              "             1.7764e-10]], device='cuda:0')},\n",
              "   29: {'step': tensor(844944.),\n",
              "    'exp_avg': tensor([-3.8750e-04, -6.3170e-04,  9.5734e-05,  2.3350e-03, -3.8799e-04,\n",
              "            -2.5512e-04,  7.3402e-04, -1.1222e-04,  6.3386e-06,  1.0158e-03,\n",
              "             1.1592e-05,  1.1594e-03,  5.5775e-04,  4.0791e-04, -4.0973e-04,\n",
              "            -1.2828e-05, -1.5069e-04, -1.1709e-03, -1.1647e-04, -4.9723e-04,\n",
              "            -1.3337e-03, -1.0355e-03,  4.1411e-04,  2.6984e-04, -1.1969e-04,\n",
              "            -3.8925e-04, -2.3880e-04, -3.2840e-05, -1.3264e-03,  2.4707e-04,\n",
              "             1.7934e-04,  2.2115e-04, -1.1342e-04,  4.1913e-04, -3.2654e-04,\n",
              "             8.9355e-04,  7.0046e-04,  3.8974e-04, -1.0081e-03, -1.2325e-06],\n",
              "           device='cuda:0'),\n",
              "    'exp_avg_sq': tensor([1.1688e-05, 6.4707e-06, 8.8459e-06, 2.2184e-05, 4.4265e-06, 2.4891e-06,\n",
              "            3.9412e-06, 3.5711e-06, 2.0148e-06, 1.1277e-05, 4.7603e-06, 8.6165e-06,\n",
              "            7.8439e-06, 4.3365e-06, 3.6587e-06, 1.9237e-06, 4.7363e-06, 1.5238e-05,\n",
              "            7.8722e-06, 1.4414e-06, 4.8161e-06, 8.9334e-06, 5.6876e-06, 1.1008e-05,\n",
              "            2.9464e-06, 5.0241e-06, 4.6697e-07, 4.0792e-06, 9.2928e-06, 9.7666e-06,\n",
              "            1.5998e-06, 1.6654e-05, 2.3266e-06, 1.0562e-06, 3.4079e-06, 4.1279e-06,\n",
              "            4.0486e-06, 1.9697e-06, 7.2546e-06, 1.7289e-07], device='cuda:0')}},\n",
              "  'param_groups': [{'lr': 0.001,\n",
              "    'betas': (0.9, 0.999),\n",
              "    'eps': 1e-08,\n",
              "    'weight_decay': 0,\n",
              "    'amsgrad': False,\n",
              "    'maximize': False,\n",
              "    'foreach': None,\n",
              "    'capturable': False,\n",
              "    'params': [0,\n",
              "     1,\n",
              "     2,\n",
              "     3,\n",
              "     4,\n",
              "     5,\n",
              "     6,\n",
              "     7,\n",
              "     8,\n",
              "     9,\n",
              "     10,\n",
              "     11,\n",
              "     12,\n",
              "     13,\n",
              "     14,\n",
              "     15,\n",
              "     16,\n",
              "     17,\n",
              "     18,\n",
              "     19,\n",
              "     20,\n",
              "     21,\n",
              "     22,\n",
              "     23,\n",
              "     24,\n",
              "     25,\n",
              "     26,\n",
              "     27,\n",
              "     28,\n",
              "     29]}]},\n",
              " 'loss': 0.4193683723680324,\n",
              " 'acc': 86.57963680957278}"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.load('model_checkpoint.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdLMWfEpyGOB"
      },
      "source": [
        "Now, it is time to finally run your ablations! Have fun!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "MG4F77Nm0Am9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/25\n",
            "\tTrain Loss: 0.7448\n",
            "\tValidation Accuracy: 81.40%\n",
            "\n",
            "Epoch 2/25\n",
            "\tTrain Loss: 0.5949\n",
            "\tValidation Accuracy: 83.01%\n",
            "\n",
            "Epoch 3/25\n",
            "\tTrain Loss: 0.5527\n",
            "\tValidation Accuracy: 83.88%\n",
            "\n",
            "Epoch 4/25\n",
            "\tTrain Loss: 0.5277\n",
            "\tValidation Accuracy: 84.33%\n",
            "\n",
            "Epoch 5/25\n",
            "\tTrain Loss: 0.5105\n",
            "\tValidation Accuracy: 84.73%\n",
            "\n",
            "Epoch 6/25\n",
            "\tTrain Loss: 0.4974\n",
            "\tValidation Accuracy: 85.01%\n",
            "\n",
            "Epoch 7/25\n",
            "\tTrain Loss: 0.4869\n",
            "\tValidation Accuracy: 85.16%\n",
            "\n",
            "Epoch 8/25\n",
            "\tTrain Loss: 0.4781\n",
            "\tValidation Accuracy: 85.33%\n",
            "\n",
            "Epoch 9/25\n",
            "\tTrain Loss: 0.4709\n",
            "\tValidation Accuracy: 85.55%\n",
            "\n",
            "Epoch 10/25\n",
            "\tTrain Loss: 0.4648\n",
            "\tValidation Accuracy: 85.66%\n",
            "\n",
            "Epoch 11/25\n",
            "\tTrain Loss: 0.4591\n",
            "\tValidation Accuracy: 85.81%\n",
            "\n",
            "Epoch 12/25\n",
            "\tTrain Loss: 0.4541\n",
            "\tValidation Accuracy: 85.88%\n",
            "\n",
            "Epoch 13/25\n",
            "\tTrain Loss: 0.4498\n",
            "\tValidation Accuracy: 85.94%\n",
            "\n",
            "Epoch 14/25\n",
            "\tTrain Loss: 0.4457\n",
            "\tValidation Accuracy: 86.06%\n",
            "\n",
            "Epoch 15/25\n",
            "\tTrain Loss: 0.4422\n",
            "\tValidation Accuracy: 86.15%\n",
            "\n",
            "Epoch 16/25\n",
            "\tTrain Loss: 0.4388\n",
            "\tValidation Accuracy: 86.15%\n",
            "\n",
            "Epoch 17/25\n",
            "\tTrain Loss: 0.4358\n",
            "\tValidation Accuracy: 86.24%\n",
            "\n",
            "Epoch 18/25\n",
            "\tTrain Loss: 0.4329\n",
            "\tValidation Accuracy: 86.32%\n",
            "\n",
            "Epoch 19/25\n",
            "\tTrain Loss: 0.4303\n",
            "\tValidation Accuracy: 86.36%\n",
            "\n",
            "Epoch 20/25\n",
            "\tTrain Loss: 0.4278\n",
            "\tValidation Accuracy: 86.34%\n",
            "\n",
            "Epoch 21/25\n",
            "\tTrain Loss: 0.4254\n",
            "\tValidation Accuracy: 86.44%\n",
            "\n",
            "Epoch 22/25\n",
            "\tTrain Loss: 0.4232\n",
            "\tValidation Accuracy: 86.38%\n",
            "\n",
            "Epoch 23/25\n",
            "\tTrain Loss: 0.4212\n",
            "\tValidation Accuracy: 86.54%\n",
            "\n",
            "Epoch 24/25\n",
            "\tTrain Loss: 0.4194\n",
            "\tValidation Accuracy: 86.58%\n",
            "\n",
            "Epoch 25/25\n",
            "\tTrain Loss: 0.4175\n",
            "\tValidation Accuracy: 86.57%\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3b6dc0efe1ec4eed86ed9190546bf453",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train loss</td><td></td></tr><tr><td>validation accuracy</td><td></td></tr><tr><td>validation loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train loss</td><td>0.41755</td></tr><tr><td>validation accuracy</td><td>86.56921</td></tr><tr><td>validation loss</td><td>-0.8657</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">cyl_v12_H8_W1745_C30_noMP_1664482261</strong>: <a href=\"https://wandb.ai/idl-group/hw1p2/runs/2dnbbiks\" target=\"_blank\">https://wandb.ai/idl-group/hw1p2/runs/2dnbbiks</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20220929_161101-2dnbbiks/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Iterate over number of epochs to train and evaluate your model\n",
        "if device == 'cuda':\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "best_acc = 0.0 ### Monitor best accuracy in your run\n",
        "\n",
        "for epoch in range(hparams.epochs):\n",
        "    print(\"\\nEpoch {}/{}\".format(epoch+1, hparams.epochs))\n",
        "\n",
        "    train_loss = train(model, optimizer, criterion, train_loader, use_wandb, mixed_pr=hparams.mixed_precision)\n",
        "    val_loss, accuracy = eval(model, val_loader, use_wandb)\n",
        "\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    print(\"\\tTrain Loss: {:.4f}\".format(train_loss))\n",
        "    print(\"\\tValidation Accuracy: {:.2f}%\".format(accuracy))\n",
        "\n",
        "    ### Save checkpoint if accuracy is better than your current best\n",
        "    if accuracy >= best_acc:\n",
        "      best_acc = accuracy\n",
        "\n",
        "      ### Save checkpoint with information you want\n",
        "      torch.save({'epoch': epoch,\n",
        "              'model_state_dict': model.state_dict(),\n",
        "              'optimizer_state_dict': optimizer.state_dict(),\n",
        "              'loss': train_loss,\n",
        "              'acc': accuracy}, \n",
        "        './model_checkpoint.pth')\n",
        "      \n",
        "      ### Save checkpoint in wandb\n",
        "      if use_wandb:\n",
        "        wandb.save('checkpoint.pth')\n",
        "\n",
        "### Finish your wandb run\n",
        "if use_wandb:\n",
        "  run.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kXwf5YUo_4A"
      },
      "source": [
        "# Testing and submission to Kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WI1hSFYLpJvH"
      },
      "source": [
        "Before we get to the following code, make sure to see the format of submission given in *random_submission.csv*. Once you have done so, it is time to fill the following function to complete your inference on test data. Refer the eval function from previous cells to get an idea of how to go about completing this function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "R-SU9fZ3xHtk"
      },
      "outputs": [],
      "source": [
        "def test(model, test_loader):\n",
        "  ### What you call for model to perform inference?\n",
        "  model.eval()\n",
        "\n",
        "  ### List to store predicted phonemes of test data\n",
        "  test_predictions = []\n",
        "\n",
        "  ### Which mode do you need to avoid gradients?\n",
        "  with torch.no_grad():\n",
        "\n",
        "      for i, frames in enumerate(tqdm(test_loader)):\n",
        "\n",
        "          frames = frames.float().to(device)             \n",
        "          \n",
        "          output = model(frames)\n",
        "\n",
        "          ### Get most likely predicted phoneme with argmax\n",
        "          predicted_phonemes = torch.argmax(output, dim=1)\n",
        "\n",
        "          test_predictions.extend(predicted_phonemes.cpu().tolist())\n",
        "\n",
        "          ### How do you store predicted_phonemes with test_predictions? Hint, look at eval \n",
        "          \n",
        "  return test_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "wG9v6Xmxu7wp"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ec0bb917233641fe9b6afcef0fdc1deb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1891 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "predictions = test(model, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "ZE1hRnvf0bFz"
      },
      "outputs": [],
      "source": [
        "### Create CSV file with predictions\n",
        "with open(\"./submission.csv\", \"w+\") as f:\n",
        "    f.write(\"id,label\\n\")\n",
        "    for i in range(len(predictions)):\n",
        "        f.write(\"{},{}\\n\".format(i, predictions[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "LjcammuCxMKN"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/jbajor/.kaggle/kaggle.json'\n",
            "100%|| 18.6M/18.6M [00:03<00:00, 6.15MB/s]\n",
            "Successfully submitted to Frame-Level Speech Recognition"
          ]
        }
      ],
      "source": [
        "### Submit to kaggle competition using kaggle API\n",
        "!kaggle competitions submit -c 11-785-f22-hw1p2 -f ./submission.csv -m \"Test Submission\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "z4vZbDmJvMp1",
        "ZIi0Big7vPa9",
        "Vuzce0_TdcaR",
        "qNacQ8bpt9nw",
        "2mlwaKlDt_2c",
        "Nxjwve20JRJ2",
        "HejoSXe3vMVU",
        "IBwunYpyugFg",
        "yMd_XxPku5qp",
        "nclx_04fu7Dd",
        "_kXwf5YUo_4A"
      ],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.6 ('dl')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "10dcf7d0c74d3b5187da3e113dd39bd34402e63079129b42ab727bb0278d4ecf"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
